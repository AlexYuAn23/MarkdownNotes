# 大数据

[TOC]

## 哈希函数

**特点：**

- 基础
	- 无限的输入域，有限的输出域
	- 相同的输入值会得到相同的输出值
	- 不同的输入值可能得到不同的输出值，也可能得到相同的输出值
- 评价优劣
	- 不同的输入值得到的输出值尽可能均匀的分布在输出域上

**哈希函数的经典实现：**MD5, SHA1

## Map-Reduce

Map-Reduce 分为两个步骤：

- Map 阶段：把大任务分成子任务
- Reduce 阶段：子任务并发处理，然后合并结果

**简单应用案例：**统计一篇文章中每个单词出现的次数

![Map-Reduce.png](http://ox7712i91.bkt.clouddn.com/Map-Reduce.png)

## 案例一

> **题目：**对 10 亿个 IPV4 IP 地址排序（地址无重复）。

用 bitmap，就是一个长度为$2^{32}$的比特数组，每个位置代表一个 IP，出现过就置 1，没出现过就置 0，然后扫描整个比特数组，得到被置 1 位置代表的 IP 即可，类似计数排序。

## 案例二

> **题目：**对 10 亿人的年龄进行排序。

在 0 ~ 200 进行计数排序。

## 案例三

> **题目：**找出一个存有 20 亿个 32 位整数的大文件中出现次数最多的数（内存限制 2G）。

如果用 hashmap，key (4B) + value (4B) = 8B，20 亿个数最多可能需要 20 亿个键值对，需要 14.9G 左右的空间，显然这种方法是不行的。

使用哈希函数进行分流，将文件中的整数分成 8 个文件，因为相同的数产生的哈希值是一样的，我们不会把相同的数分去不同的文件，并且哈希函数的输出是均匀的，所以每个文件的大小应该相差无几，然后在对每个小文件进行统计，最后返回 8 个文件中出现次数最多的数中出现次数最多的那个数。

## 案例四

> **题目：**32 位无符号整数（0 ~ 4294967295），现在有一个包含 40 亿无符号整数的文件，用 10M 内存找出一个没出现过的数（找出一个即可）。

把 0 ~ 4294967295 分成 16 个小段，给每段建立一个 bitmap。

## 案例五

> **题目：**百亿搜索词，找出每天最热的 100 词。

用到的方法：分流 + 大根堆

![百亿词频统计.png](http://ox7712i91.bkt.clouddn.com/%E7%99%BE%E4%BA%BF%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1.png)

## 案例六

> **题目：**使用服务器集群来设计和实现数据缓存，常见策略有：
>
> - 增查删都先将数据的 id 转换成哈希值 key
> - 计算 key%N 找到该数据所属的机器编号
>
> 这样做有什么潜在问题，更好的做法是怎样的。

**潜在问题：**增加删除机器的代价很高，因为通过 %N 来计算数据的归属机器，一旦 N 发生了变化，要对所有机器上的数据归属进行重新分配。

**解决方法：**一致性哈希算法。

### 一致性哈希算法

![一致性哈希算法.png](http://ox7712i91.bkt.clouddn.com/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95.png)

